{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eyestatus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install scipy==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQzdstB_hRfI",
        "outputId": "53228931-23b4-45bd-b92a-93ca3fc26b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.3.8 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJqaaA2VdEVT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from scipy.ndimage import imread\n",
        "from scipy.misc import imresize, imsave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 24\n",
        "\n",
        "def collect():\n",
        "\ttrain_datagen = ImageDataGenerator(\n",
        "\t\t\trescale=1./255,\n",
        "\t\t\tshear_range=0.2,\n",
        "\t\t\thorizontal_flip=True, \n",
        "\t\t)\n",
        "\n",
        "\tval_datagen = ImageDataGenerator(\n",
        "\t\t\trescale=1./255,\n",
        "\t\t\tshear_range=0.2,\n",
        "\t\t\thorizontal_flip=True,\t\t)\n",
        "\n",
        "\ttrain_generator = train_datagen.flow_from_directory(\n",
        "\t    directory=\"/content/drive/MyDrive/dataset/train\",\n",
        "\t    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "\t    color_mode=\"grayscale\",\n",
        "\t    batch_size=32,\n",
        "\t    class_mode=\"binary\",\n",
        "\t    shuffle=True,\n",
        "\t    seed=42\n",
        "\t)\n",
        "\n",
        "\tval_generator = val_datagen.flow_from_directory(\n",
        "\t    directory=\"/content/drive/MyDrive/dataset/val\",\n",
        "\t    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "\t    color_mode=\"grayscale\",\n",
        "\t    batch_size=32,\n",
        "\t    class_mode=\"binary\",\n",
        "\t    shuffle=True,\n",
        "\t    seed=42\n",
        "\t)\n",
        "\treturn train_generator, val_generator\n",
        "\n",
        "\n",
        "def save_model(model):\n",
        "\tmodel_json = model.to_json()\n",
        "\twith open(\"/content/drive/MyDrive/model.json\", \"w\") as json_file:\n",
        "\t\tjson_file.write(model_json)\n",
        "\t# serialize weights to HDF5\n",
        "\tmodel.save_weights(\"/content/drive/MyDrive/model.h5\")\n",
        "\n",
        "def load_model():\n",
        "\tjson_file = open('/content/drive/MyDrive/model.json', 'r')\n",
        "\tloaded_model_json = json_file.read()\n",
        "\tjson_file.close()\n",
        "\tloaded_model = model_from_json(loaded_model_json)\n",
        "\t# load weights into new model\n",
        "\tloaded_model.load_weights(\"/content/drive/MyDrive/model.h5\")\n",
        "\tloaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn loaded_model\n",
        "\n",
        "def train(train_generator, val_generator):\n",
        "\tSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "\tSTEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
        "\n",
        "\tprint('[LOG] Intialize Neural Network')\n",
        "\t\n",
        "\tmodel = Sequential()\n",
        "\n",
        "\tmodel.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\n",
        "\tmodel.add(AveragePooling2D())\n",
        "\n",
        "\tmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "\tmodel.add(AveragePooling2D())\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\n",
        "\tmodel.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "\tmodel.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "\tmodel.add(Dense(units=1, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\tmodel.fit_generator(generator=train_generator,\n",
        "\t                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "\t                    validation_data=val_generator,\n",
        "\t                    validation_steps=STEP_SIZE_VALID,\n",
        "\t                    epochs=20\n",
        "\t)\n",
        "\tsave_model(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "l_AjV8y3kW8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(img, model):\n",
        "\timg = Image.fromarray(img, 'RGB').convert('L')\n",
        "\timg = imresize(img, (IMG_SIZE,IMG_SIZE)).astype('float32')\n",
        "\timg /= 255\n",
        "\timg = img.reshape(1,IMG_SIZE,IMG_SIZE,1)\n",
        "\tprediction = model.predict(img)\n",
        "\tif prediction < 0.1:\n",
        "\t\tprediction = 'closed'\n",
        "\telif prediction > 0.9:\n",
        "\t\tprediction = 'open'\n",
        "\telse:\n",
        "\t\tprediction = 'idk'\n",
        "\treturn prediction\n",
        "\n",
        "def evaluate(X_test, y_test):\n",
        "\tmodel = load_model()\n",
        "\tprint('Evaluate model')\n",
        "\tloss, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
        "\tprint(acc * 100)\n",
        "\n",
        "if __name__ == '__main__':\t\n",
        "\ttrain_generator , val_generator = collect()\n",
        "\ttrain(train_generator,val_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MA6fCedmcig",
        "outputId": "4217cfae-ded4-4938-8559-b9ebcadaf874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3819 images belonging to 2 classes.\n",
            "Found 1067 images belonging to 2 classes.\n",
            "[LOG] Intialize Neural Network\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "119/119 [==============================] - 714s 6s/step - loss: 0.6122 - accuracy: 0.6514 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.4232 - accuracy: 0.8104 - val_loss: 0.3755 - val_accuracy: 0.8381\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.3266 - accuracy: 0.8635 - val_loss: 0.3307 - val_accuracy: 0.8693\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 7s 60ms/step - loss: 0.2787 - accuracy: 0.8886 - val_loss: 0.3098 - val_accuracy: 0.8674\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.2523 - accuracy: 0.9034 - val_loss: 0.2548 - val_accuracy: 0.8892\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 7s 62ms/step - loss: 0.2096 - accuracy: 0.9203 - val_loss: 0.2231 - val_accuracy: 0.9205\n",
            "Epoch 7/20\n",
            "119/119 [==============================] - 8s 63ms/step - loss: 0.1949 - accuracy: 0.9258 - val_loss: 0.2202 - val_accuracy: 0.9119\n",
            "Epoch 8/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.1809 - accuracy: 0.9329 - val_loss: 0.2196 - val_accuracy: 0.9025\n",
            "Epoch 9/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.1672 - accuracy: 0.9356 - val_loss: 0.1892 - val_accuracy: 0.9309\n",
            "Epoch 10/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.1561 - accuracy: 0.9432 - val_loss: 0.1723 - val_accuracy: 0.9290\n",
            "Epoch 11/20\n",
            "119/119 [==============================] - 7s 59ms/step - loss: 0.1470 - accuracy: 0.9480 - val_loss: 0.1812 - val_accuracy: 0.9261\n",
            "Epoch 12/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.1476 - accuracy: 0.9488 - val_loss: 0.1725 - val_accuracy: 0.9309\n",
            "Epoch 13/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.1343 - accuracy: 0.9511 - val_loss: 0.1881 - val_accuracy: 0.9318\n",
            "Epoch 14/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.1335 - accuracy: 0.9535 - val_loss: 0.1541 - val_accuracy: 0.9441\n",
            "Epoch 15/20\n",
            "119/119 [==============================] - 7s 60ms/step - loss: 0.1299 - accuracy: 0.9511 - val_loss: 0.1748 - val_accuracy: 0.9280\n",
            "Epoch 16/20\n",
            "119/119 [==============================] - 7s 60ms/step - loss: 0.1259 - accuracy: 0.9530 - val_loss: 0.1497 - val_accuracy: 0.9413\n",
            "Epoch 17/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.1161 - accuracy: 0.9538 - val_loss: 0.1530 - val_accuracy: 0.9337\n",
            "Epoch 18/20\n",
            "119/119 [==============================] - 7s 61ms/step - loss: 0.1185 - accuracy: 0.9548 - val_loss: 0.1733 - val_accuracy: 0.9290\n",
            "Epoch 19/20\n",
            "119/119 [==============================] - 7s 62ms/step - loss: 0.1155 - accuracy: 0.9570 - val_loss: 0.1499 - val_accuracy: 0.9347\n",
            "Epoch 20/20\n",
            "119/119 [==============================] - 7s 60ms/step - loss: 0.1080 - accuracy: 0.9596 - val_loss: 0.1451 - val_accuracy: 0.9394\n"
          ]
        }
      ]
    }
  ]
}